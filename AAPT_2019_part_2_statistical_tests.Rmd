---
title: "AAPT Summer 2019 Stats WS: Part 1"
author: "Jayson Nissen, John Buncher, Daryl McPadden, & Rachel Henderson"
date: "7/21/2019"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(effsize) #33 kb
library(knitr)
library(tidyr)
library(dplyr)

#setwd("~/Documents/GitHub/Stats-WS-master/Stats_WS") #set the working directory to a folder for this project. It makes life easier.

std.err <- function(x) sqrt(var(x,na.rm=TRUE)/length(na.omit(x)))

#Color blind palletes for making figures
plot_col <- c('#66c2a5', '#fc8d62', '#8da0cb')
cbbpalette <- c('#000000','#E69F00','#56B4E9')
```

# Step 0 - Import the Dataset
We need to import a new dataset to analyze.  We’ll again assume our data comes in the form of pre- and posttest data from a concept inventory (“CI”) that was administered before and after course instruction.  

To easily import data into R, click the "Import Dataset" button in the top-right panel in the "Environment" tab.  Import your group's assigned dataset (A, B, C, or D), and make sure the data gets named "my_ci_data"!  If you'd rather import using the command line, complete the R code in the blank chunk below:

```{r}
#my_ci_data <- 
```

# Step 1: Visualize the Data
Using the code from Part 1 as a reference, fill out the following blank chunk to generate box plots, histograms and scatter plots for the data using GGPLOT.  Code to generate these plots using base R is provided below the blank space.

## ggplot code to produce box plots, histograms, & scatter plots
```{r}

```

## Scatter plot
The following code will create a scatter plot of posttest scores vs. pretest scores.
```{r}
plot(my_ci_data$pre, my_ci_data$post, main='Pre/Post Scatter Plot', xlab = "Pre", ylab="Post")
abline(0,1)
```
## Boxplot
```{r}
boxplot(with(ci_data, data.frame(pre, post)), main='Boxplots of Pretest and Posttest Scores')
```

## Histograms
```{r}
hist(ci_data$pre, col = rgb(1,0,0,0.4), xlab = 'Score', ylab='Count', main='Distribution of Pretest Score')
```


```{r}
hist(ci_data$post, col = rgb(0,0,1,0.4), xlab = 'Score', ylab='Count', main='Distribution of Posttest Scores')
```

```{r}
# Note that this is a terrible way to make a histogram. We highly recommend learning ggplot 
# and the tidyverse.
## calculate the histograms - don't plot yet
histpre <- hist(ci_data$pre, plot = FALSE, breaks=10)
histpost <- hist(ci_data$post, plot = FALSE, breaks=10)
## calculate the range of the graph
xlim <- range(histpre$breaks, histpost$breaks)
ylim <- range(0,histpre$counts,
              histpost$counts)
## plot the first graph
plot(histpre,xlim = xlim, ylim = ylim,
     col = rgb(1,0,0,0.4), xlab = 'Score', ylab='Count',
     freq = TRUE, ## relative, not absolute frequency
     main = 'Distribution of Pretest and Posttest Scores')
## plot the second graph on top of this
opar <- par(new = FALSE)
plot(histpost,xlim = xlim, ylim = ylim,
     xaxt = 'n', yaxt = 'n', ## don't add axes
     col = rgb(0,0,1,0.4), add = TRUE,
     freq = TRUE) ## relative, not absolute frequency
## add a legend in the corner
legend('topleft',c('Pre','Post'),
       fill = rgb(1:0,0,0:1,0.4), bty = 'n',
       border = NA)
par(opar)
```

Make a density plot comparing pre and posttest scores using ggplot
```{r}

```

Now we want to calculate the descriptive statistics for the data. There are a lot of ways to do this. We are going to use the "describe"" function in the "psych" package. Kable is a function for markdown documents that creates tables.
```{r}
library(psych)
sumstats <- describe(ci_data)
print(sumstats)

kable(sumstats, digits=1)
```

Now we need to determine what type of statistical tests that we want to run.
The most common test for pre/post concept inventories is a matched t-test. Before we run the test we want to check that the data meets the assumptions for the test. These assumptions include:

1. The data is measured on a continuous scale.
2. The data is matched across two groups.
3. There are no major outliers in the differences between the groups
4. The distributions of the differences are approximately normally distributed

Discuss 1 and 2 and decide if the data meets these assumptions.
Earlier we produced boxplots of the pretest and posttest that identified outliers in those scores. We can do the same for the gains to identify outliers in the difference between the scores.

```{r pressure, echo=FALSE}
boxplot(ci_data[c(2)], main='Boxplot of Gains') #This is a boxplot of the gains
points(mean(ci_data$gain), col="blue", bg="blue", pch=16) #This adds a point for the mean to provide a visual representation of the difference between the mean and median.
```
The boxplot can show how far apart the mean and median are and how symmetric the data is. We can look back at our summary statistics table to determine if our data is too far from normal to use a t-test on. A normal distribution has a skew of 0 and a kurtosis of 0. Accepted limits for both skewness and kurtosis are -2 and +2 [George, D., & Mallery, M. (2010). SPSS for Windows Step by Step: A Simple Guide and Reference, 17.0 update (10a ed.) Boston: Pearson].

If we are satisfied that the data meet our assumptions then we can run our t-test
```{r}
t.test(ci_data$post,ci_data$pre, paired = TRUE, var.equal=TRUE)
```
If we are worried about the variances then we can run a second test
```{r}
t.test(ci_data$post,ci_data$pre, paired = TRUE, var.equal = FALSE)
```

Now we need to interpret all of the values from the t.test.

It is also important to calculate the effect size for the difference. Often in PER researchers will use normalized gain, but there is very little work validating normalized gain as a reliable measure. We recommend using a variant of Cohen's d, which is the difference between two distributions divided by the pooled standard deviation. It is important to note that the effect sizes for matched samples and for unmatched samples are slightly different. Therefore, researchers need to be aware of which one they are using and which one they are comparing their results to. Here we calculate Hedge's g, which is a variant of Cohen's d that corrects for small sample sizes.

```{r}
library(effsize)
cohen.d(ci_data$post,ci_data$pre,paired=TRUE,hedges.correction = TRUE)
```
Note that the output gives us an interpretation of these values based on rules of thumb provided by Cohen. These rules of thumb don't necessarily apply to CI data and should not be used. Instead use your own interpretation and results from other courses to say whether this is a meaningful difference.

Do you think that this is a meaningful difference?


If you have finished and are waiting for the group discussion feel free to explore these ideas with your group.

+ What is a p-value? What does and what doesn't a p-value tell us? Why is 0.05 our cutoff?
++ Check out the resources here https://tinyurl.com/statworkshopresources to learn more.
+ What are type 1 and type 2 error and why are they both important? Calculate the Beta for your analysis.

Below here will be deleted and moved into a challenge document.
Generating Likert Scale Data in R

```{r}
att_data <- data.frame(pre =  sample(0:4, 100, replace = TRUE, prob = c(0.1, 0.2, 0.4, 0.2, 0.1)),
                       post = sample(0:4, 100, replace = TRUE, prob = c(0.1, 0.1, 0.3, 0.3, 0.2)))

plot_data <- gather(att_data, key="time", value = "score")

ggplot(data=plot_data, aes(x=score, group=time, fill=time) ) + 
  geom_bar(alpha=0.5, position = position_dodge()) +
  theme(plot.title = element_text(hjust = 0.5))+
  labs(title = "Histogram of Pretest Scores", y="Count", x= "Test Score (%)")

write.csv(att_data, file="challenge_data.csv")
```

