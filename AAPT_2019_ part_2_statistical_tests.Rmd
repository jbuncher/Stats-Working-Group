---
title: "Stats WS"
author: "Jayson Nissen"
date: "5/7/2018"
output: pdf_document
---
Notes on things to cover.
How markdown works.
Loading data.
Using the help menu.
Adding and loading packages.


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(msm) #this has the rtnorm function for generating the data.

#library(tidyr)
library(psych) #contains describe function 3.3 MB
#library(knitr) #634 kb
library(effsize) #33 kb
library(cowplot)
library(knitr)
library(tidyr)
library(dplyr)

#setwd("~/Documents/GitHub/Stats-WS-master/Stats_WS") #set the working directory to a folder for this project. It makes life easier.

std.err <- function(x) sqrt(var(x,na.rm=TRUE)/length(na.omit(x)))

#Color blind palletes for making figures
plot_col <- c('#66c2a5', '#fc8d62', '#8da0cb')
cbbpalette <- c('#000000','#E69F00','#56B4E9')

```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

Load the data set
```{r}

```


Part 2 - Data Analysis

Generating the data

Load the dataset
```{r}

```


Use the prior code to generate box plots, histograms and scatter plots for the data using GGPLOT. Here is the code using base.

```{r}

```

```{r}
plot(ci_data$pre,ci_data$post, main='Pre/Post Scatter Plot', xlab = "Pre", ylab="Post")
abline(0,1)
```
Boxplot
```{r}
boxplot(ci_data[c(1,3)], main='Boxplots of Pretest and Posttest Scores')
```
Histograms
```{r}
hist(ci_data$pre,col = rgb(1,0,0,0.4),xlab = 'Score', ylab='Count', main='Distribution of Pretest Score')
```


```{r}
hist(ci_data$post,col = rgb(0,0,1,0.4),xlab = 'Score', ylab='Count', main='Distribution of Posttest Scores')
```

```{r}
#Note that this is a terrible way to make a histogram. We highly recommend learning ggplot and the tidyverse.
## calculate the histograms - don't plot yet
histpre <- hist(ci_data$pre,plot = FALSE, breaks=10)
histpost <- hist(ci_data$post,plot = FALSE, breaks=10)
## calculate the range of the graph
xlim <- range(histpre$breaks,histpost$breaks)
ylim <- range(0,histpre$counts,
              histpost$counts)
## plot the first graph
plot(histpre,xlim = xlim, ylim = ylim,
     col = rgb(1,0,0,0.4),xlab = 'Score', ylab='Count',
     freq = TRUE, ## relative, not absolute frequency
     main = 'Distribution of Pretest and Posttest Scores')
## plot the second graph on top of this
opar <- par(new = FALSE)
plot(histpost,xlim = xlim, ylim = ylim,
     xaxt = 'n', yaxt = 'n', ## don't add axes
     col = rgb(0,0,1,0.4), add = TRUE,
     freq = TRUE) ## relative, not absolute frequency
## add a legend in the corner
legend('topleft',c('Pre','Post'),
       fill = rgb(1:0,0,0:1,0.4), bty = 'n',
       border = NA)
par(opar)
```

Make a density plot comparing pre and posttest scores using ggplot
```{r}

```

Now we want to calculate the descriptive statistics for the data. There are a lot of ways to do this. We are going to use the describe function in the Psych package. Kable is a function for markdown documents that creates tables.
```{r eval=FALSE, include=FALSE}
sumstats<-describe(ci_data)
print(sumstats)

kable(sumstats, digits=1)
```

Now we need to determine what type of statistical tests that we want to run.
The most common test for pre/post concept inventories is a matched t-test. Before we run the test we want to check that the data meets the assumptions for the test. These assumptions include:
1. The data is measured on a continuous scale.
2. The data is matched across two groups.
3. There are no major outliers in the differences between the groups
4. The distributions of the differences are approximately normally distributed

Discuss 1 and 2 and decide if the data meets these assumptions.
Earlier we produced boxplots of the pretest and posttest that identified outliers in those scores. We can do the same for the gains to identify outliers in the difference between the scores.

```{r pressure, echo=FALSE}
boxplot(ci_data[c(2)], main='Boxplot of Gains') #This is a boxplot of the gains
points(mean(ci_data$gain), col="blue", bg="blue", pch=16) #This adds a point for the mean to provide a visual representation of the difference between the mean and median.
```
The boxplot can show how far apart the mean and median are and how symmetric the data is. We can look back at our summary statistics table to determine if our data is too far from normal to use a t-test on. A normal distribution has a skew of 0 and a kurtosis of 0. Accepted limits for both skewness and kurtosis are -2 and +2 [George, D., & Mallery, M. (2010). SPSS for Windows Step by Step: A Simple Guide and Reference, 17.0 update (10a ed.) Boston: Pearson].

If we are satisfied that the data meet our assumptions then we can run our t-test
```{r}
t.test(ci_data$post,ci_data$pre, paired = TRUE, var.equal=TRUE)
```
If we are worried about the variances then we can run a second test
```{r}
t.test(ci_data$post,ci_data$pre, paired = TRUE, var.equal = FALSE)
```

Now we need to interpret all of the values from the t.test.

It is also important to calculate the effect size for the difference. Often in PER researchers will use normalized gain, but there is very little work validating normalized gain as a reliable measure. We recommend using a variant of Cohen's d, which is the difference between two distributions divided by the pooled standard deviation. It is important to note that the effect sizes for matched samples and for unmatched samples are slightly different. Therefore, researchers need to be aware of which one they are using and which one they are comparing their results to. Here we calculate Hedge's g, which is a variant of Cohen's d that corrects for small sample sizes.

```{r}
library(effsize)
cohen.d(ci_data$post,ci_data$pre,paired=TRUE,hedges.correction = TRUE)
```
Note that the output gives us an interpretation of these values based on rules of thumb provided by Cohen. These rules of thumb don't necessarily apply to CI data and should not be used. Instead use your own interpretation and results from other courses to say whether this is a meaningful difference.

Do you think that this is a meaningful difference?


If you have finished and are waiting for the group discussion feel free to explore these ideas with your group.

+ What is a p-value? What does and what doesn't a p-value tell us? Why is 0.05 our cutoff?
++ Check out the resources here https://tinyurl.com/statworkshopresources to learn more.
+ What are type 1 and type 2 error and why are they both important? Calculate the Beta for your analysis.

Below here will be deleted and moved into a challenge document.
Generating Likert Scale Data in R

```{r}
att_data <- data.frame(pre =  sample(0:4, 100, replace = TRUE, prob = c(0.1, 0.2, 0.4, 0.2, 0.1)),
                       post = sample(0:4, 100, replace = TRUE, prob = c(0.1, 0.1, 0.3, 0.3, 0.2)))

plot_data <- gather(att_data, key="time", value = "score")

ggplot(data=plot_data, aes(x=score, group=time, fill=time) ) + 
  geom_bar(alpha=0.5, position = position_dodge()) +
  theme(plot.title = element_text(hjust = 0.5))+
  labs(title = "Histogram of Pretest Scores", y="Count", x= "Test Score (%)")

write.csv(att_data, file="challenge_data.csv")
```

