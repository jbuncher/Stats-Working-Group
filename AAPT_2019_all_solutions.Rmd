---
title: "Stats WS"
author: "Jayson Nissen"
date: "5/7/2018"
output: pdf_document
---
Notes on things to cover.
How markdown works.
Loading data.
Using the help menu.
Adding and loading packages.


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(msm) #this has the rtnorm function for generating the data.

library(psych) #contains describe function 3.3 MB
library(effsize) #33 kb
library(knitr)
library(ggplot2)
library(tidyr)
library(dplyr)

setwd("~/Documents/GitHub/Stats-WS-master") #set the working directory to a folder for this project. It makes life easier.

#std.err <- function(x) sqrt(var(x,na.rm=TRUE)/length(na.omit(x)))

#Color blind palletes for making figures 
#  http://www.cookbook-r.com/Graphs/Colors_(ggplot2)/
plot_col <- c('#66c2a5', '#fc8d62', '#8da0cb')
cbbpalette <- c('#000000','#E69F00','#56B4E9')

```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

Build the datasets
Replace this with uploading the dataset. Make sure we have a nice big dataset that works well
Since this is for the solutions you can see how we generated the data.

```{r, include=FALSE}
set.seed(45637268)
ci_data <- data.frame(pre= rtnorm(n=1000,mean=30,sd=24,lower=0,upper=100),
                      gain= rtnorm(n=1000,mean=12,sd=35,lower=-10,upper=70))
ci_data$post <- ci_data$pre + ci_data$gain
ci_data$post[ci_data$post>100] <- rtnorm(n=1000, mean=80, sd=10, lower=60, upper=100)
#ci_data$post[ci_data$post>100] <- 100
ci_data$post[ci_data$post<0] <- rtnorm(n=1000, mean=8, sd=8, lower=0, upper=30)
ci_data$gain <- ci_data$post-ci_data$pre
write.csv(ci_data, file="for_visualizations.csv")
```

Load the data
```{r}
ci_data <- read.csv("for_visualizations.csv")
```


Build representations of the data.
Scatter plot
```{r}
plot(ci_data$pre,ci_data$post, main='Pre/Post Scatter Plot', xlab = "Pre", ylab="Post")
abline(0,1)
```
Boxplot
```{r}
boxplot(ci_data[c("pre","post")], main='Boxplots of Pretest and Posttest Scores')
```
Histograms
```{r}
hist(ci_data$pre,col = rgb(1,0,0,0.4),xlab = 'Score', ylab='Count', main='Distribution of Pretest Score')
```

```{r}
hist(ci_data$post,col = rgb(0,0,1,0.4),xlab = 'Score', ylab='Count', main='Distribution of Posttest Scores')
```

```{r}
#Note that this is a terrible way to make a histogram. We highly recommend learning ggplot and the tidyverse.
## calculate the histograms - don't plot yet
histpre <- hist(ci_data$pre,plot = FALSE, breaks=10)
histpost <- hist(ci_data$post,plot = FALSE, breaks=10)
## calculate the range of the graph
xlim <- range(histpre$breaks,histpost$breaks)
ylim <- range(0,histpre$counts,
              histpost$counts)
## plot the first graph
plot(histpre,xlim = xlim, ylim = ylim,
     col = rgb(1,0,0,0.4),xlab = 'Score', ylab='Count',
     freq = TRUE, ## relative, not absolute frequency
     main = 'Distribution of Pretest and Posttest Scores')
## plot the second graph on top of this
opar <- par(new = FALSE)
plot(histpost,xlim = xlim, ylim = ylim,
     xaxt = 'n', yaxt = 'n', ## don't add axes
     col = rgb(0,0,1,0.4), add = TRUE,
     freq = TRUE) ## relative, not absolute frequency
## add a legend in the corner
legend('topleft',c('Pre','Post'),
       fill = rgb(1:0,0,0:1,0.4), bty = 'n',
       border = NA)
par(opar)
```
Stop!

Discuss these visualizations with your group and we will have a large group discussion before we move on to making visualization with ggplot.


Now we want to work through this using ggplot.
```{r}
ggplot(data=ci_data, aes(x=pre)) + 
  geom_histogram() +
  theme_minimal()

ggplot(data=ci_data, aes(x=pre)) + 
  geom_histogram(color="red", fill= "green", alpha=0.5) +
  theme_minimal()

ggplot(data=ci_data, aes(x=pre)) + 
  geom_histogram(color="red", fill= "green", alpha=0.5) +
  labs(title = "Histogram of Pretest Scores", y="Count", x= "Test Score (%)")

ggplot(data=ci_data, aes(x=pre)) + 
  geom_histogram(color="red", fill= "green", alpha=0.5) +
  theme(plot.title = element_text(hjust = 0.5))+
  labs(title = "Histogram of Pretest Scores", y="Count", x= "Test Score (%)")

ggplot(data=ci_data, aes(x=pre)) + 
  geom_density(color="red", fill= "green", alpha=0.5) +
  theme(plot.title = element_text(hjust = 0.5))+
  labs(title = "Histogram of Pretest Scores", y="Count", x= "Test Score (%)")

```

Now we want to make comparisons, which requires reformating the data. ggplot works on the premise that all of the data is in a single vector and different vectors have information about the groupings that we will need.

To make side by side histograms in ggplot we need to put all of the test scores into one column and the pre/posttest names into a different column.

```{r}
plot_data <- gather(ci_data[c("pre","post")], key="time", value = "score") # change to the column names

ggplot(data=plot_data, aes(x=score, group=time, fill=time) ) + 
  geom_histogram(alpha=0.5, position = "identity") +
  theme(plot.title = element_text(hjust = 0.5))+
  labs(title = "Histogram of Pretest Scores", y="Count", x= "Test Score (%)")
```

Activity! Use the ci_data and/or plot_data to create 
(1) a scatter plot, 
(2) a box plot, and 
(3) a density plot.

```{r}
ggplot(data=ci_data, aes(x=pre, y=post)) + 
  geom_point(color="black", alpha=0.5) +
  theme(plot.title = element_text(hjust = 0.5))+
  labs(title = "Student Scores", y="Posttest Score (%)", x= "Pretest Score (%)")
```

```{r}
#Switching the order to pre then post

plot_data$time <- factor(plot_data$time, levels=c("pre","post"))

ggplot(data=plot_data, aes(x=time , y=score, group=time, fill=time) ) + 
  geom_boxplot(alpha=0.5, position = "identity") +
  theme(plot.title = element_text(hjust = 0.5))+
  labs(title = "Boxplots of Pretest and Posttest Scores", y="Test Score (%)", x= "Time")
```

```{r}
#Switching the order to pre then post

plot_data$time <- factor(plot_data$time, levels=c("pre","post"))

ggplot(data=plot_data, aes(group=time , x=score, group=time, fill=time) ) + 
  geom_density(alpha=0.5, position = "identity") +
  theme(plot.title = element_text(hjust = 0.5))+
  labs(title = "Density Plots of Test Scores", y="Density", x= "Test Score (%)")
```

Additional things to do:
Change the colors
Add fit line to the scatter plot
Change the Alpha
Modify the legend
Any other ideas that you have that we should share with everyone.

Changing the colors to use the color blind pallette and modify the legend
```{r}
plot_data$time <- factor(plot_data$time, levels=c("pre","post")) #Switching the order to pre then post

plot_1 <- ggplot(data=plot_data, aes(group=time , x=score, group=time, fill=time) ) + 
  geom_density(alpha=0.5, position = "identity") +
  theme(plot.title = element_text(hjust = 0.5))+
  labs(title = "Density Plots of Test Scores", y="Density", x= "Test Score (%)")+ 
  scale_fill_manual(
    values = cbbpalette,
    breaks = c("pre", "post"), #this and the following line can be cut and it doesn't change anything they can also be used to change the order (I think)
    labels = c("Pretest", "Posttest")
)

plot_1

plot_1 +
theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
panel.background = element_blank(), axis.line = element_line(colour = "black"), legend.title = element_blank(), legend.position = c(0.8,0.8))

```

add a fit line to the scatter plot
```{r}
plot_1 <- ggplot(data=ci_data, aes(x=pre, y=post)) + 
  geom_point(color="black", alpha=0.5) +
  theme(plot.title = element_text(hjust = 0.5))+
  labs(title = "Student Scores", y="Posttest Score (%)", x= "Pretest Score (%)")

plot_1 + geom_smooth(method='lm',formula=y~x, se=FALSE)
```

Extra Activity: Use the plot data with the extra course variable to divide it into two groups and create a faceted density plot with pre and post density plots or historgrams for both groups (i.e., facet by course)
```{r}
plot_data$course <- sample(x=c("Course One","Course Two"), prob = c(0.5,0.5))

plot_data$time <- factor(plot_data$time, levels=c("pre","post")) #Switching the order to pre then post

ggplot(data=plot_data, aes(group=time , x=score, group=time, fill=time) ) + 
  geom_density(alpha=0.5, position = "identity") +
  theme(plot.title = element_text(hjust = 0.5))+
  labs(title = "Density Plots of Test Scores", y="Density", x= "Test Score (%)")+ 
  scale_fill_manual(
    values = cbbpalette,
    breaks = c("pre", "post"), #this and the following line can be cut and it doesn't change anything they can also be used to change the order (I think)
    labels = c("Pretest", "Posttest")
) +
theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
panel.background = element_blank(), axis.line = element_line(colour = "black"), legend.title = element_blank(), legend.position = c(0.8,0.8)) +
  facet_wrap(~course)


```


Part 2 - Data Analysis


Load the dataset
```{r}
ci_data <- read.csv("ci_data_B.csv") # this can be run through all four data sets: A, B, C, and D by replacing the letter. If it doesn't work it is because the working directory isn't set correctly or the file isn't in the working directory.
```


Use the prior code to generate box plots, histograms and scatter plots for the data using GGPLOT. Here is the code using base.

```{r}
plot_1 <- ggplot(data=ci_data, aes(x=pre, y=post)) + 
  geom_point(color="black", alpha=0.5) +
  theme(plot.title = element_text(hjust = 0.5))+
  labs(title = "Student Scores", y="Posttest Score (%)", x= "Pretest Score (%)")

plot_1 + geom_smooth(method='lm',formula=y~x, se=FALSE)
```

```{r}
plot_data <- gather(ci_data[c("pre","post")], key="time", value = "score") # change to the column names

plot_data$time <- factor(plot_data$time, levels=c("pre","post"))

ggplot(data=plot_data, aes(x=time , y=score, group=time, fill=time) ) + 
  geom_boxplot(alpha=0.5, position = "identity") +
  theme(plot.title = element_text(hjust = 0.5))+
  labs(title = "Boxplots of Pretest and Posttest Scores", y="Test Score (%)", x= "Time")
```

```{r}
plot_data$time <- factor(plot_data$time, levels=c("pre","post")) #Switching the order to pre then post

plot_1 <- ggplot(data=plot_data, aes(group=time , x=score, group=time, fill=time) ) + 
  geom_density(alpha=0.5, position = "identity") +
  theme(plot.title = element_text(hjust = 0.5))+
  labs(title = "Density Plots of Test Scores", y="Density", x= "Test Score (%)")+ 
  scale_fill_manual(
    values = cbbpalette,
    breaks = c("pre", "post"), #this and the following line can be cut and it doesn't change anything they can also be used to change the order (I think)
    labels = c("Pretest", "Posttest")
)

plot_1

plot_1 +
theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
panel.background = element_blank(), axis.line = element_line(colour = "black"), legend.title = element_blank(), legend.position = c(0.8,0.8))

```

```{r}
plot_data$time <- factor(plot_data$time, levels=c("pre","post")) #Switching the order to pre then post

plot_1 <- ggplot(data=plot_data, aes(group=time , x=score, group=time, fill=time) ) + 
  geom_histogram(alpha=0.5, position = "identity") +
  theme(plot.title = element_text(hjust = 0.5))+
  labs(title = "Density Plots of Test Scores", y="Density", x= "Test Score (%)")+ 
  scale_fill_manual(
    values = cbbpalette,
    breaks = c("pre", "post"), #this and the following line can be cut and it doesn't change anything they can also be used to change the order (I think)
    labels = c("Pretest", "Posttest")
)

plot_1

plot_1 +
theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
panel.background = element_blank(), axis.line = element_line(colour = "black"), legend.title = element_blank(), legend.position = c(0.8,0.8))

```

```{r}
plot(ci_data$pre,ci_data$post, main='Pre/Post Scatter Plot', xlab = "Pre", ylab="Post")
abline(0,1)
```
Boxplot
```{r}
boxplot(ci_data[c(2,4)], main='Boxplots of Pretest and Posttest Scores')
```
Histograms
```{r}
hist(ci_data$pre,col = rgb(1,0,0,0.4),xlab = 'Score', ylab='Count', main='Distribution of Pretest Score')
```


```{r}
hist(ci_data$post,col = rgb(0,0,1,0.4),xlab = 'Score', ylab='Count', main='Distribution of Posttest Scores')
```

```{r}
#Note that this is a terrible way to make a histogram. We highly recommend learning ggplot and the tidyverse.
## calculate the histograms - don't plot yet
histpre <- hist(ci_data$pre,plot = FALSE, breaks=10)
histpost <- hist(ci_data$post,plot = FALSE, breaks=10)
## calculate the range of the graph
xlim <- range(histpre$breaks,histpost$breaks)
ylim <- range(0,histpre$counts,
              histpost$counts)
## plot the first graph
plot(histpre,xlim = xlim, ylim = ylim,
     col = rgb(1,0,0,0.4),xlab = 'Score', ylab='Count',
     freq = TRUE, ## relative, not absolute frequency
     main = 'Distribution of Pretest and Posttest Scores')
## plot the second graph on top of this
opar <- par(new = FALSE)
plot(histpost,xlim = xlim, ylim = ylim,
     xaxt = 'n', yaxt = 'n', ## don't add axes
     col = rgb(0,0,1,0.4), add = TRUE,
     freq = TRUE) ## relative, not absolute frequency
## add a legend in the corner
legend('topleft',c('Pre','Post'),
       fill = rgb(1:0,0,0:1,0.4), bty = 'n',
       border = NA)
par(opar)
```

Make a density plot comparing pre and posttest scores using ggplot
```{r}

```

Now we want to calculate the descriptive statistics for the data. There are a lot of ways to do this. We are going to use the describe function in the Psych package. Kable is a function for markdown documents that creates tables.
```{r eval=FALSE, include=FALSE}
sumstats<-describe(ci_data)
print(sumstats)

kable(sumstats, digits=1)
```

Now we need to determine what type of statistical tests that we want to run.
The most common test for pre/post concept inventories is a matched t-test. Before we run the test we want to check that the data meets the assumptions for the test. These assumptions include:
1. The data is measured on a continuous scale.
2. The data is matched across two groups.
3. There are no major outliers in the differences between the groups
4. The distributions of the differences are approximately normally distributed

Discuss 1 and 2 and decide if the data meets these assumptions.
Earlier we produced boxplots of the pretest and posttest that identified outliers in those scores. We can do the same for the gains to identify outliers in the difference between the scores.

```{r pressure, echo=FALSE}
boxplot(ci_data$gain, main='Boxplot of Gains') #This is a boxplot of the gains
points(mean(ci_data$gain), col="blue", bg="blue", pch=16) #This adds a point for the mean to provide a visual representation of the difference between the mean and median.
```
The boxplot can show how far apart the mean and median are and how symmetric the data is. We can look back at our summary statistics table to determine if our data is too far from normal to use a t-test on. A normal distribution has a skew of 0 and a kurtosis of 0. Accepted limits for both skewness and kurtosis are -2 and +2 [George, D., & Mallery, M. (2010). SPSS for Windows Step by Step: A Simple Guide and Reference, 17.0 update (10a ed.) Boston: Pearson].

If we are satisfied that the data meet our assumptions then we can run our t-test
```{r}
t.test(ci_data$post,ci_data$pre, paired = TRUE, var.equal=TRUE)
```
If we are worried about the variances then we can run a second test
```{r}
t.test(ci_data$post,ci_data$pre, paired = TRUE, var.equal = FALSE)
```

Now we need to interpret all of the values from the t.test. Discuss them with your group.

It is also important to calculate the effect size for the difference. Often in PER researchers will use normalized gain, but there is very little work validating normalized gain as a reliable measure. We recommend using a variant of Cohen's d, which is the difference between two distributions divided by the pooled standard deviation. It is important to note that the effect sizes for matched samples and for unmatched samples are slightly different. Therefore, researchers need to be aware of which one they are using and which one they are comparing their results to. Here we calculate Hedge's g, which is a variant of Cohen's d that corrects for small sample sizes.

```{r}
library(effsize)
cohen.d(ci_data$post,ci_data$pre,paired=TRUE,hedges.correction = TRUE)
```
Note that the output gives us an interpretation of these values based on rules of thumb provided by Cohen. These rules of thumb don't necessarily apply to CI data and should not be used. Instead use your own interpretation and results from other courses to say whether this is a meaningful difference.

Do you think that this is a meaningful difference?


If you have finished and are waiting for the group discussion feel free to explore these ideas with your group.

+ What is a p-value? What does and what doesn't a p-value tell us? Why is 0.05 our cutoff?
++ Check out the resources here https://tinyurl.com/statworkshopresources to learn more.
+ What are type 1 and type 2 error and why are they both important? Calculate the Beta for your analysis.

Below here will be deleted and moved into a challenge document.
Generating Likert Scale Data in R

```{r}
att_data <- data.frame(pre =  sample(0:4, 100, replace = TRUE, prob = c(0.1, 0.2, 0.4, 0.2, 0.1)),
                       post = sample(0:4, 100, replace = TRUE, prob = c(0.1, 0.1, 0.3, 0.3, 0.2)))

plot_data <- gather(att_data, key="time", value = "score")

ggplot(data=plot_data, aes(x=score, group=time, fill=time) ) + 
  geom_bar(alpha=0.5, position = position_dodge()) +
  theme(plot.title = element_text(hjust = 0.5))+
  labs(title = "Histogram of Pretest Scores", y="Count", x= "Test Score (%)")

write.csv(att_data, file="challenge_data.csv")
```

# Part III: The challenge data.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(msm) #this has the rtnorm function for generating the data.

#library(tidyr)
library(psych) #contains describe function 3.3 MB
#library(knitr) #634 kb
library(effsize) #33 kb
library(cowplot)
library(knitr)
library(tidyr)
library(dplyr)
library(ggplot2)

setwd("~/Documents/GitHub/Stats-WS-master") #set the working directory to a folder for this project. It makes life easier.

#Color blind palletes for making figures
plot_col <- c('#66c2a5', '#fc8d62', '#8da0cb')
cbbpalette <- c('#000000','#E69F00','#56B4E9')

```

## Part III.A: Visualization of the Challenge Dataset

Now that we've loaded the packages that we will need for the challenge, import the challenge dataset and take a look at it.

```{r, include=FALSE}
chal_data <- read.csv("challenge_data.csv")
View(chal_data)
```




Build representations of the data.

Does a scatter plot make sense for this type of data?

```{r}
plot(chal_data$pre,chal_data$post, main='Pre/Post Scatter Plot', xlab = "Pre", ylab="Post")
abline(0,1)
```

What about a boxplot?

```{r}
boxplot(chal_data[c(2,4)], main='Boxplots of Pretest and Posttest Scores')
```


What about a histogram?

```{r}
hist(chal_data$pre,col = rgb(1,0,0,0.4),xlab = 'Score', ylab='Count', main='Distribution of Pretest Score')
```
```{r}
hist(chal_data$post,col = rgb(0,0,1,0.4),xlab = 'Score', ylab='Count', main='Distribution of Posttest Scores')
```

```{r}
#Note that this is a terrible way to make a histogram. We highly recommend learning ggplot and the tidyverse.
## calculate the histograms - don't plot yet
histpre <- hist(chal_data$pre,plot = FALSE, breaks=10)
histpost <- hist(chal_data$post,plot = FALSE, breaks=10)
## calculate the range of the graph
xlim <- range(histpre$breaks,histpost$breaks)
ylim <- range(0,histpre$counts,
              histpost$counts)
## plot the first graph
plot(histpre,xlim = xlim, ylim = ylim,
     col = rgb(1,0,0,0.4),xlab = 'Score', ylab='Count',
     freq = TRUE, ## relative, not absolute frequency
     main = 'Distribution of Pretest and Posttest Scores')
## plot the second graph on top of this
opar <- par(new = FALSE)
plot(histpost,xlim = xlim, ylim = ylim,
     xaxt = 'n', yaxt = 'n', ## don't add axes
     col = rgb(0,0,1,0.4), add = TRUE,
     freq = TRUE) ## relative, not absolute frequency
## add a legend in the corner
legend('topleft',c('Pre','Post'),
       fill = rgb(1:0,0,0:1,0.4), bty = 'n',
       border = NA)
par(opar)
```

Stop!

Discuss these visualizations with your group and then move on to making visualization with ggplot.


Now we want to make comparisons, which requires reformating the data. ggplot works on the premise that all of the data is in a single vector and different vectors have information about the groupings that we will need.

To make side by side barplots in ggplot we need to put all of the test scores into one column and the pre/posttest names into a different column.

```{r}
plot_data <- gather(chal_data[c("pre","post")], key="time", value = "score")

ggplot(data=plot_data, aes(x=score, group=time, fill=time) ) + 
  geom_bar(alpha=0.5, position = position_dodge()) +
  theme(plot.title = element_text(hjust = 0.5))+
  labs(title = "Bar Plot of Test Scores", y="Count", x= "Raw Score")
```

Activity! Use the ch_data and/or plot_data to create 
(1) pie charts of pre and post,
(2) pie charts or bar charts faceted,
(3) bar chart with bars over top of one another.

```{r}
as.data.frame(table(chal_data$pre)) %>% 
    rename(class=Var1, cnt=Freq) %>%
    ggplot(mapping = aes(x = "", y=cnt, fill = factor(class))) + 
        geom_bar(width = 1, stat="identity")+
        geom_text(aes(label=cnt), 
              size=6,
              #ensure text is printed in the middle of slice: vjust=0.5
              position = position_stack(vjust = 0.5))+
        #theta/angle is proportionl to count i.e. y
        coord_polar(theta = "y") 
```


## Part III.B: Analyzing the Challenge Dataset
Now we want to calculate the descriptive statistics for the data. There are a lot of ways to do this. Before we used the describe function in the Psych package and the Kablefunction for markdown documents that creates tables.

Does this provide all of the descriptive statistics that we need? Are there any other statistics that we want?

```{r}
sumstats<-describe(chal_data)
print(sumstats)

kable(sumstats, digits=1)
```

Now we need to determine what type of statistical tests that we want to run.
Last time for the pre/post data we used a matched t-test. However, DOES THIS DATA MEET THE ASSUMPTIONS OF A T-TEST? Reminder, these assumptions include:
1. The data is measured on a continuous scale.
2. The data is matched across two groups.
3. There are no major outliers in the differences between the groups
4. The distributions of the differences are approximately normally distributed

Here, the pre/post data is ranked data on a scale from 1 to 5 and therefore, the first assumption of continuous data is violated. We need to use a different statistical test. There are many different non-parametric statistical tests that can be used on ranked data; we suggest using the Mann-Whitney U statisical test (also called the Wilcoxon rank-sum test) and Cliff's Delta for the effect size.


```{r}
wilcox.test(chal_data$post,chal_data$pre, paired=TRUE)
cliff.delta(chal_data$post,chal_data$pre, conf.level=.95)
```

Cliff's delta is limited to a value between -1 and 1 which is different from Cohen's d. The Cliff's delta values that correspond to small, medium, and large effect sizes are of 0.147, 0.33, and 0.474, respectively (see Cohen, 1969 pg. 23 for further details)

Do you think that this is a meaningful difference? Discuss in your group.

How do these compare to the p-value and effect size from a t-test? 



Here is the code for generating this data. Make sure that you understand all of the parts of the code. Then you can mess around with the pieces and see how that impacts the visualizations and statistical tests.

```{r}
chal_data <- data.frame(pre =  sample(c(1:5), 1000, replace=TRUE, prob=c(0.15, 0.35, 0.25, 0.15,0.1) ),
                        gain= sample(c(-2:2), 1000, replace=TRUE, prob=c(0.1, 0.1, 0.3, 0.3 ,0.2) ))
chal_data$post <- chal_data$pre + chal_data$gain
chal_data$post[chal_data$post>5] <- sample(c(3:5), 1000, replace=TRUE, prob=c(0.25, 0.25,0.5) )

chal_data$post[chal_data$post<1] <- sample(c(1:3), 1000, replace=TRUE, prob=c(0.5, 0.25,0.25) )
#write.csv(chal_data, file="challenge_data.csv")
```




